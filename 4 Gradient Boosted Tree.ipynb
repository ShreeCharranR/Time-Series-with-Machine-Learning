{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Tree is similar to random forest models, but the difference is that trees are built successively. With each iteration, the next tree fits the residual errors from the previous tree in order to improve the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t-12  t-11  t-10   t-9   t-8   t-7   t-6   t-5   t-4   t-3   t-2   t-1  \\\n",
       "0  10.0   9.0  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   \n",
       "1   9.0  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0   \n",
       "2  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0   \n",
       "3 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0  -4.0   \n",
       "4 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0  -4.0 -16.0   \n",
       "\n",
       "      t  \n",
       "0   3.0  \n",
       "1  13.0  \n",
       "2  -4.0  \n",
       "3 -16.0  \n",
       "4 -20.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df1 = pd.read_csv('vacation_lags_12months_features.csv', header=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "vacat = df1.values\n",
    "# split into lagged variables and original time series\n",
    "X1= vacat[:, 0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y1 = vacat[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column t, which is the original time series\n",
    "# y1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 174\n",
      "Training Observations for Target: 130\n",
      "Testing Observations for Target: 44\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y1 = y1\n",
    "traintarget_size = int(len(Y1) * 0.75)   # Set split\n",
    "train_target, test_target = Y1[0:traintarget_size], Y1[traintarget_size:len(Y1)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y1)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 174\n",
      "Training Observations for feature: 130\n",
      "Testing Observations for feature: 44\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X1) * 0.75)\n",
    "train_feature, test_feature = X1[0:trainfeature_size], X1[trainfeature_size:len(X1)]\n",
    "print('Observations for feature: %d' % (len(X1)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977569663400098\n",
      "0.719890154142028\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Regression Model\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters \n",
    "gbr = GradientBoostingRegressor(max_features=2,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x1 = range(X1.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x1, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Bank of America Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.687537</td>\n",
       "      <td>1.469485</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.469485</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "      <td>1.941008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "      <td>1.941008</td>\n",
       "      <td>1.707245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t-12      t-11      t-10       t-9       t-8       t-7       t-6  \\\n",
       "0  1.687537  1.469485  1.441042  1.525887  1.476664  1.412676  1.341841   \n",
       "1  1.469485  1.441042  1.525887  1.476664  1.412676  1.341841  0.879137   \n",
       "2  1.441042  1.525887  1.476664  1.412676  1.341841  0.879137  0.709480   \n",
       "3  1.525887  1.476664  1.412676  1.341841  0.879137  0.709480  0.987102   \n",
       "4  1.476664  1.412676  1.341841  0.879137  0.709480  0.987102  1.002662   \n",
       "\n",
       "        t-5       t-4       t-3       t-2       t-1         t  \n",
       "0  0.879137  0.709480  0.987102  1.002662  1.232781  1.282093  \n",
       "1  0.709480  0.987102  1.002662  1.232781  1.282093  1.595426  \n",
       "2  0.987102  1.002662  1.232781  1.282093  1.595426  1.699101  \n",
       "3  1.002662  1.232781  1.282093  1.595426  1.699101  1.941008  \n",
       "4  1.232781  1.282093  1.595426  1.699101  1.941008  1.707245  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data, this data has been stationarized\n",
    "df3 = pd.read_csv('bac_lags_12months_features.csv', header=0)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "\n",
    "bac = df3.values\n",
    "# split into lagged variables (features) and original time series data (target)\n",
    "X3= bac[:,0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y3 = bac[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68753707,  1.46948457,  1.44104242, ...,  0.98710191,\n",
       "         1.00266206,  1.23278129],\n",
       "       [ 1.46948457,  1.44104242,  1.52588725, ...,  1.00266206,\n",
       "         1.23278129,  1.28209293],\n",
       "       [ 1.44104242,  1.52588725,  1.47666395, ...,  1.23278129,\n",
       "         1.28209293,  1.59542644],\n",
       "       ...,\n",
       "       [30.09263229, 28.80098343, 26.88482857, ..., 26.28380585,\n",
       "        28.81011391, 30.47911263],\n",
       "       [28.80098343, 26.88482857, 27.76469421, ..., 28.81011391,\n",
       "        30.47911263, 27.32987022],\n",
       "       [26.88482857, 27.76469421, 24.22343063, ..., 30.47911263,\n",
       "        27.32987022, 29.17000008]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28209293, 1.59542644, 1.69910097, 1.94100773, 1.70724475,\n",
       "       1.65948939, 1.91634405, 1.76750135, 1.85432637, 1.70548344])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column t, which is the original time series\n",
    "# Give first 10 values of target variable, time series\n",
    "y3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 345\n",
      "Training Observations for Target: 258\n",
      "Testing Observations for Target: 87\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y3 = y3\n",
    "traintarget_size = int(len(Y3) * 0.75)   # Set split\n",
    "train_target, test_target = Y3[0:traintarget_size], Y3[traintarget_size:len(Y3)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y3)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 345\n",
      "Training Observations for feature: 258\n",
      "Testing Observations for feature: 87\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X3) * 0.75)\n",
    "train_feature, test_feature = X3[0:trainfeature_size], X3[trainfeature_size:len(X3)]\n",
    "print('Observations for feature: %d' % (len(X3)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99460446666043\n",
      "0.9521949350955565\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters\n",
    "gbr = GradientBoostingRegressor(max_features=8,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x3 = range(X3.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x3, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we looked at a Gradient Boosted model on a dataset that consisted of 12 lagged variables.  The dataset was split into features and target. It was further split according to a training and testing datasets.  In some ways, the feature importances of the Gradient Boosted model are similar to those of the feature importances of the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
